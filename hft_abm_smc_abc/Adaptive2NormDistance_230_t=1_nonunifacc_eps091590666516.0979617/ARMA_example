"""Purpose of this script is to simlate observations from ARMA,
define model and its true parameters, give prior distribution"""

import numpy as np
import matplotlib.pyplot as plt
import pyabc.visualization
import logging
import statsmodels as sm
from statsmodels import tsa
from statsmodels.tsa import arima_process, arima_model
from pyabc import Distribution, RV, History
import pyabc


np.random.seed(12345)

# for debugging
df_logger = logging.getLogger('Distance')
df_logger.setLevel(logging.DEBUG)



# model definition
def arma_model(p):

    # Further, due to the conventions used in signal processing used in signal.lfilter vs.
    # conventions in statistics for ARMA processes, the AR parameters should have the opposite sign of what you might expect.
    arparams = np.array([p["ar1"]])
    maparams = np.array([p["ma1"]])

    # coefficients
    # coefficient on the zero-lag. This is typically 1.
    ar = np.r_[1, -arparams]  # add zero-lag and negate
    ma = np.r_[1, maparams] # add zero-lag

    y = sm.tsa.arima_process.arma_generate_sample(ar, ma, 500)

    ss = {}
    for j in range(500):
        ss['p0_' + str(j)] = y[j]

    return ss

# true model parameter
param_dict = {"ar1": -0.75, "ma1":0.65}

# observation
ss_dict = arma_model(param_dict)

# test optimisation:
# Fits ARMA(p,q) model using exact maximum likelihood via Kalman filter.
model_fit = sm.tsa.arima_model.ARMA(list(ss_dict.values()), (1, 1)).fit(trend='nc', disp=0)
model_fit.params

# prior distribution
# Parameters as Random Variables
prior = Distribution(ar1=RV("uniform", -1, 0.5),
                     ma1=RV("uniform", 0, 1))

# database
db_path = pyabc.create_sqlite_db_id(file_="arma_model1.db")

distance_adaptive = pyabc.AdaptivePNormDistance(p=2, scale_function=pyabc.distance.root_mean_square_deviation)

abc = pyabc.ABCSMC(
    arma_model, prior, distance_adaptive,
    population_size=100,
    acceptor=pyabc.UniformAcceptor(use_complete_history=True))

abc.new(db_path, ss_dict)

history1 = abc.run(minimum_epsilon=.1, max_nr_populations=8)

from pyabc.visualization import plot_kde_matrix
df, w = history1.get_distribution(m=0, t=7)
plot_kde_matrix(df, w);
plt.show()


def plot_coonvergence(history, parameter, range_min, range_max, true_value, ax):
    #fig, ax = plt.subplots()
    for t in range(history.max_t-1):
        df, w = history.get_distribution(m=0, t=t)
        pyabc.visualization.plot_kde_1d(
            df, w,
            xmin=range_min, xmax=range_max,
            x=parameter, ax=ax,
            label="PDF t={}".format(t))
    ax.axvline(true_value, color="k", linestyle="dashed");
    ax.legend(prop={'size': 6});


fig, axs = plt.subplots(2,1)
plot_coonvergence(history1, 'ar1', -1, 0.5, -0.75, ax=axs[0])
plot_coonvergence(history1, 'ma1', 0, 1, 0.65, ax=axs[1])
plt.show()